Common Tricks

General:

* Clarify what assumptions I am making.
* Start thinking in the middle of the problems; then think of how to start and end
* If can’t optimize the hard problem - do the brute force (or any problem). Always have a solution.
* Boundary conditions / cases: begin end middle shorter longer equal duplicates null empty ; positive negative numbers; 0 multiplication or division; int or float.
* For code implementation: think general (code covers most cases), then sub-specialize.
* I must think of operations with negative numbers and details of boundaries and possible cases at different locations and combinations of values.
* Backwards trick: work back/for; work on target vs input; two-pass trick; replay last to first move.
* Trick: if any order, counter may help.
* In stack: we can keep indices not just values
* Stack: when stuff increasing and decreasing and need to keep ordering straight; or need to do stuff with something that just happened; overlaps thinking with two pointers in some way. 
* The 2 finger dP; if there are two unindistinguashable options: finger 1 could be finger 2: just say finger move (whichever) if no condition on their order/sequence.
* In trees: settle on thinking bottom up or top down; do not mix the thinking.
—————————————
Arithmetics

- Minint, Maxint:- 2**31; 2**31 - 1; notice more negatives than pos so may be better to work with negatives in some cases (like the integer divisor problem).
- Exponential search: double the value you subtract or add every time.
- ———————————————
Arrays

* 2 pointers and other (such as tree advance; or pq): advance pointers 1 at a time is best. I notice I overdo it with while. And both p1 and p2 at a time.

* Sometimes an array problem can be viewed : min into max such as min len at the end = max len in between

* When aggregating in a matrix: think bottom right corner

* Sometimes think in aggregates: eg if x > 1 then nx > n

* When thinking: how to ascertain that I have a certain number of something left in the remaining slice (see pizza cut): think prefix sums; run length: left to right; bottom up or both

* Run lengths: keeping count left right up down and cumsums (see pizza question)

* Trick: add left and right in an array (on sides; can be val of 1; float(inf) etc) (like DL: think padding)

* To visualize how an index moves: remember the cloud / boundary idea.

* To keep track of a change we can change the value to negative (-value). That way we know there was a change and also we still know the old value (if assumed pos int) and we don’t need an auxiliary array

* If values of nums[I] are in the range of the indices, think of using comparison between values and indices.

* Square root decomposition for range sum queries: split data in blocks of sqrt(n) length and hold block sums. Then in a range query must look at full blocks and partial blocks both before and after. (P307.)

———————————

Recursion: (w/o memo):
——————————

* For some problems (such as stock problems), think a decision at point i of “do” vs “not do” something with something.

* Trick: add and subtract to keep track of 2 players!! Or start and end; or open and close - matching or scoring.

———————————————

DP tricks:

* Cherry pick idea: r+c = t (num of steps (0,0) to (roc)); 1 person 2 roads == 2 people 1 road.
* When seeing (in DP / recursion) dependencies on two sides, may think of two recurse calls on two different subintervals that combine to give answer at step i.

* DP (from MIT course) approach/steps for both TD(memo) and BU (not necessary sequential steps); Time must be polynomial time:
- 1. Split subproblems: frist priority is suffixes (a[I:]); then prefixes (a[:I]) then sub-seq(a[I:j])
- 2. Make a guess: (eg: which path to here (index i) blah blah); typically have a cost per path)
- 3. Optimize (take a min; max over choices guessed): (eg)for j in (I+1, n): dp[I] += dp[j] etc.
- 4. Build recursion (memo) or dp table; check acyclic (topo order); calculate O(); figure out base case (when I = n or something like that).
- Solve initial problem: typically call dp(0) preferably.

* DP on trees: deems a common trick is to think of splitting in subtrees and thinking the relationship between subtree1_nodes_statistics and subtree2_node_statistcs.

* ! Sometimes bfs can be confused with backtracking or dp but you want bfs because it can be linear time. The clues for bfs are: look for min path; the cost from 1 step to the next is always constant and = 1. (In dp case, the cost is typically != 1 and variable). Before bfs a greedy is even more optimal but careful when it misses possibilities.

* DP: mask & 1 << i (bit masking); mask | (1 << i) +  more practice on different types of problems and 2D dp.


——————————————————
Trees:

* Bin trees: seems that a unique id for nodes helps in many instances.
* Cans use bin search to navigate a BST.
* you can keep order with linking left and right across level.

—————————————————————
————————————————————————

Queu/Stack / Greedy:

* Greedy: with heaps, sorts,  binary search or stacks/queueus.

* Clue to use queue: something of length k - sliding window
* Clue to use stack: processing something from the past at a later time

* Notice that bin search and greedy can be used at times ( when I think of recursion and DP ). Seems to be a thing to turn the question upside down(see division of chocolate problems); Look into indices; have a sorted array of indices we can look for with bin search - if sorted- think bin search since O(long); If “consecutive - think something is sorted”.


—————————————————
Typical q to ask:

- Does the index start with 1?
- Does the timestamp start with 0?
- Must all elements be used?
- Are there duplicates?
- What can be duplicated?
- Where (end, begin, middle, does it matter)?
- Nones, zeros
- Type of input: int, pos, neg, float.
- What other constraints, assumptions am I or the problem making?
- Can change input?


———
Python!
Functools.reduce(gcd, nums)
math.gcd(a, b)
